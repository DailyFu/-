{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>实验\n",
    "    \n",
    "## 线性规划方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型产生数据\n",
    "\n",
    "<center>$y=1+2x+e,e \\in N(0,1)$</center>\n",
    "    \n",
    "  $n=30，p=2 $\n",
    "  \n",
    "-  代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import linprog\n",
    "n=30\n",
    "tau=0.5\n",
    "p=2\n",
    "x = np.random.normal(0 ,1,n)\n",
    "y = 1+2*x+ np.random.normal(0 ,1,n)\n",
    "'''\n",
    "linear programing\n",
    "使用线性规划包linpro，内点法\n",
    "运行函数前先把必要的库运行好\n",
    "'''\n",
    "def fit1(tau):\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.optimize import linprog\n",
    "    A=np.hstack([np.zeros(p),tau*np.ones(n),(1-tau)*np.ones(n)])\n",
    "    a=np.ones(n).T\n",
    "    b=np.array(x)\n",
    "    B=np.vstack([a,b,np.eye(n),-np.eye(n)])\n",
    "    B=B.T\n",
    "    res = linprog(A, A_eq=B, b_eq=y)\n",
    "\n",
    "    beta_solve1=res.x[:p]#线性规划的解\n",
    "\n",
    "    u=res.x[p+1:p+1+n]\n",
    "    v=res.x[p+2+n:]\n",
    "    #u-v#线性规划所得的残差\n",
    "    return beta_solve1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outcome: $[0.85542775, 2.27101859]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次梯度方法(SubgradientMethod)\n",
    "\n",
    "- 模型产生数据\n",
    "\n",
    "和上文一样，只是令 $n=300$\n",
    "\n",
    "- 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "import time    \n",
    "n=300#最开始以n=30实验\n",
    "tau=0.5\n",
    "p=2\n",
    "x = np.random.normal(10,1,n)\n",
    "y = 1+2*x+ np.random.normal(0,1,n)\n",
    "\n",
    "X=np.vstack((np.ones(n),x))\n",
    "X=X.T\n",
    "beta_new=np.ones(p)\n",
    "beta_old=np.zeros(p)\n",
    "n_iter = 0\n",
    "start = time.clock()\n",
    "\n",
    "diff = np.max(np.abs(beta_new - beta_old))\n",
    "\n",
    "history = dict(params = [], mse=[])\n",
    "while n_iter<1000 and diff > 0.001:\n",
    "    beta_old=beta_new\n",
    "    predict=np.dot(X,beta_old)\n",
    "    e=y-predict\n",
    "    \n",
    "    mask = e==0\n",
    "    sub1=np.where(e>0,tau*X[:,1],(tau-1)*X[:,1])\n",
    "    sub1[mask]=random.uniform((tau-1)*X[:,1][mask],tau*X[:,1][mask])\n",
    "\n",
    "    sub0=np.where(e>0,tau*X[:,0],(tau-1)*X[:,0])\n",
    "    sub0[mask]=random.uniform((tau-1)*X[:,0][mask],tau*X[:,0][mask])\n",
    "\n",
    "\n",
    "    sub=np.vstack((sub0,sub1))\n",
    "    sub_gradient=np.array([np.mean(sub[0]),np.mean(sub[1])])\n",
    "    beta_new=beta_old+0.01*sub_gradient\n",
    "    diff = np.max(np.abs(beta_new - beta_old))\n",
    "    resid=np.abs(e)\n",
    "    history['params'].append(diff)\n",
    "    history['mse'].append(np.mean(resid*resid))\n",
    "    print(n_iter)\n",
    "    n_iter += 1\n",
    "\n",
    "\n",
    "elapsed = (time.clock() - start)\n",
    "print(elapsed)\n",
    "\n",
    "\n",
    "#残差图\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,beta_new[0]+beta_new[1]*x)\n",
    "plt.show()\n",
    "#待估参数收敛速度\n",
    "plt.plot(history[\"params\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **$outcome$**:\n",
    "\n",
    " 运行时间：0.011480500000061511\n",
    " \n",
    " 迭代次数：27"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **<center> 次梯度算法拟合效果 </center>**\n",
    "    \n",
    " ![image1.png](sub_gradient.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **<center>待估参数收敛速度</center>**\n",
    "\n",
    " ![image1.png](sub_gradient1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernstein Polynomials Method\n",
    "\n",
    "$\\rho_\\tau(e) is continous \\quad e \\in[a \\cdot b]$ 可以推导出在$[a \\cdot b]$的Bernstein Polynomials\n",
    "\n",
    "$\\sum_{i=0}^{n} \\rho_\\tau\\left(\\frac{(n-i) a+i b}{n}\\right) \\cdot C_{n}^{i}\\left(\\frac{e-a}{b-a}\\right)^{i}\\left(\\frac{b-e}{b-a}\\right)^{n-i}$\n",
    "\n",
    "为检验拟合效果，生成数据501个，服从$[-3 \\cdot 3]$的均匀分布多项式展开水平为20，拟合分位损失函数($\\tau$ 分别取$0,0.1,0.3,0.7,0.9,1$)的图\n",
    "\n",
    "- **代码**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def bernstein_poly_ab ( n, a, b, x ): \n",
    "    import numpy as np\n",
    "    from sys import exit\n",
    "    p = np.zeros(n + 1)      \n",
    "    p[0] = ( b - x ) / ( b - a )\n",
    "    p[1] = ( x - a ) / ( b - a ) \n",
    "    for i in range ( 2, n + 1 ):\n",
    "        p[i] = ( x - a ) * p[i-1] / ( b - a )\n",
    "        for j in range ( i - 1, 0, -1 ):\n",
    "            p[j] = ( ( b - x ) * p[j] + ( x - a ) * p[j-1] ) / ( b - a )\n",
    "        p[0] = ( b - x ) * p[0] / ( b - a )\n",
    "    return p\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "import platform\n",
    "from scipy.optimize import curve_fit\n",
    "import time\n",
    "from sys import exit\n",
    "\n",
    "a = -3.0\n",
    "b = 3.0\n",
    "#####################\n",
    "for degree in range ( 0, 21 ):\n",
    "    xdata = np.zeros ( degree + 1 )\n",
    "    ydata = np.zeros ( degree + 1 )\n",
    "    for i in range ( 0, degree + 1 ):\n",
    "        if ( degree == 0 ):\n",
    "            xdata[i] = 0.5 * ( a + b );\n",
    "        else:\n",
    "            xdata[i] = ( float ( degree - i ) * a   \\\n",
    "             + float (          i ) * b ) \\\n",
    "             / float ( degree     )\n",
    "\n",
    "        ydata[i] = np.sin ( xdata[i] )\n",
    "############################\n",
    "degree=20       \n",
    "xdata=np.linspace(a,b,degree+1)\n",
    "tau=1.0\n",
    "ydata=np.where(xdata>0,tau*xdata,(tau-1)*xdata)\n",
    "\n",
    "nval = 501\n",
    "\n",
    "xval = np.linspace ( a, b, nval )\n",
    "\n",
    "from bernstein_poly_ab import bernstein_poly_ab\n",
    "yval = np.zeros ( nval )\n",
    "for i in range ( 0, nval ):\n",
    "   bvec = bernstein_poly_ab ( degree, a, b, xval[i] )\n",
    "   yval[i] = np.dot ( ydata, bvec )\n",
    "   \n",
    "   \n",
    "   \n",
    "plt.plot(xval,yval)\n",
    "plt.plot(xdata,ydata)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "error =   abs ( yval - np.where(xval>0,tau*xval,(tau-1)*xval) ) \n",
    "\n",
    "error_max = max(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "\n",
    "![image3.png](tau(0.0).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image4.png](tau(0.1).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image5.png](tau(0.3).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](tau(0.5).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image6.png](tau(0.7).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image7.png](tau(0.9).png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image8.png](tau(1.0).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantile loss function:\n",
    "\n",
    "$\\rho_\\tau(Y-X \\beta) \\quad Y-X \\beta \\in[a \\cdot b]$\n",
    "\n",
    "the Bernstein Polynomials of quantile loss (Let $e=Y-X\\beta$):\n",
    "\n",
    "$\\sum_{i=0}^{n} \\rho_\\tau\\left(\\frac{(n-i) a+i b}{n}\\right) \\cdot C_{n}^{i}\\left(\\frac{(Y-X \\beta)-a}{b-a}\\right)^{i}\\left(\\frac{b-(Y-X \\beta)}{b-a}\\right)^{n-i}$\n",
    "\n",
    "但是如果要是估计$\\beta$的话，用高斯牛顿迭代的话，每迭代一次，$e$的区间$[a \\cdot b]$会发生变化，\n",
    "\n",
    "一阶导数为：\n",
    "\n",
    "$\\sum_{i=1}^{n-1} \\rho_\\tau\\left(\\frac{(n-i) a+i b}{n}\\right) \\cdot C_{n}^{i}\\left(\\frac{(Y-X \\beta)-a}{b-a}\\right)^{i-1}\\left(\\frac{b-(Y-X \\beta)}{b-a}\\right)^{n-i-1}\\left(n-2i\\right)X+ \\rho_\\tau(a) \\left(\\frac{b-(Y-X \\beta)}{b-a}\\right)^{n-1} X +\\rho_\\tau(a) \\left(\\frac{(Y-X \\beta)-a}{b-a}\\right)^{i-1} \\left( -X \\right)$\n",
    "\n",
    "是否每迭代一次，$[a \\cdot b]$都需要更新一次"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
